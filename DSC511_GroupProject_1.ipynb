{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Rs-klSOqnrTp",
        "5EDfdr5Rr0h7",
        "Nvj6BkU8sY7P",
        "Ru_yq9njs8lv",
        "cIzFkc0btqaS",
        "jzLLt9TEeQau",
        "u8VYgzEQrb7A",
        "0EaSGUxIodzm",
        "3vF6t1GHeYLR",
        "Ya1s5GJjVOMq"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vasiliki655/DSC511-Introduction/blob/main/DSC511_GroupProject_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DSC 511 - Big Data Analytics - Group Semester Project\n",
        "## Reviews of restaurants for pre and post-Covid-19 periods\n",
        "### Spring Semester 2025\n",
        "##### Team: Rafaela Christou, Emili Rousou, Christiana Zorzi, Vasiliki Christodoulou"
      ],
      "metadata": {
        "id": "W7AADmpKRkA2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset used for this project was sourced from Kaggle and includes two CSV files containing restaurant reviews from pre-COVID and post-COVID periods, allowing for comparative analysis of customer sentiment and behaviour over time.\n",
        "Through this analysis, we aim to understand how user behavior and sentiment changed due to the impact of COVID-19 on the restaurant industry.\n",
        "\n",
        "We tried to answer questions like:\n",
        "\n",
        "- How did the customer sentiment change over time (post and pre covid)?\n",
        "\n",
        "\n",
        "- How did the total number of reviews per restaurant change from the pre-COVID period to the post-COVID period?\n",
        "\n",
        "\n",
        "- Did the average customer star ratings for the top 15 highest-rated restaurants decline after COVID-19, and if so, which restaurants were most affected?\n",
        "\n",
        "\n",
        "- Which U.S. states had the highest number of restaurants pre-COVID vs. post-COVID?\n",
        "\n",
        "- Which states had the highest number of restaurant reviews in the pre-COVID and post-COVID periods? Did the top states in number of reviews change over time?\n",
        "\n",
        "- How accuraately the classification model (logistic regression) is predicting the sentiment of the customers reviews?\n",
        "\n",
        "- Finding the topics of the reviews pre and post Covid.\n"
      ],
      "metadata": {
        "id": "yt1BO8Jz-nO9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading libraries"
      ],
      "metadata": {
        "id": "F-IMTVVCNwN9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMswIgdMaJBx",
        "outputId": "eb085faa-9fd7-4b65-fdb5-a81bb5117056"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.11/dist-packages (3.5.1)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.11/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ],
      "source": [
        "# Installing pyspark\n",
        "! pip3 install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import matplotlib.pyplot as plt\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import *\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "from pyspark.sql.window import Window\n",
        "from pyspark.ml.clustering import LDA\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "from pyspark.ml import Pipeline\n",
        "from pyspark.ml.feature import IDF\n",
        "from pyspark.ml.linalg import Vectors, DenseVector\n",
        "from pyspark.sql.types import ArrayType, DoubleType\n",
        "from pyspark.sql.types import MapType, StringType\n",
        "import plotly.express as px\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
        "import datetime\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.sql.functions import col"
      ],
      "metadata": {
        "id": "Hu4hr54Sy3rs"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating the Spark Session"
      ],
      "metadata": {
        "id": "pIrjCct46qMD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Group_Project_Reviews_Covid\") \\\n",
        "    .master(\"local\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "otW_HDezSamD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the datasets"
      ],
      "metadata": {
        "id": "b-MSc98ITBqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Google drive and reading the csv of post dataset\n",
        "drive.mount('/content/drive')\n",
        "google_drive_path = \"/content/drive/MyDrive/postcovid_reviews.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQenpOIKSzaw",
        "outputId": "110d73cb-0bf4-4ec8-ba5a-dde8457e96fa"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Google drive and reading the csv of pre dataset\n",
        "drive.mount('/content/drive')\n",
        "google_drive = \"/content/drive/MyDrive/precovid_reviews.csv\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gT0bAYyYTQvV",
        "outputId": "264f5f9e-91e2-43c4-e200-4e8b9e24b140"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_df = spark.read.parquet(\"/content/drive/MyDrive/post_parquet\")"
      ],
      "metadata": {
        "id": "1uO785JqWkeJ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#post_df.show(10)"
      ],
      "metadata": {
        "id": "zLYgGlS_alIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drive.mount('/content/drive')\n",
        "#google_drive = \"/content/drive/MyDrive/precovid_reviews.csv\"\n",
        "#pre_df = spark.read.options(header='True', inferSchema='True', delimiter=',',multiline = True, escape = '\"').csv(google_drive_path)"
      ],
      "metadata": {
        "id": "SWppwKGmVVEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pre_df.write.mode(\"overwrite\").parquet(\"/content/drive/MyDrive/pre_parquet\")\n",
        "#os.listdir(\"/content/drive/MyDrive/pre_parquet\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "FZqgBNJ_X2EP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df = spark.read.parquet(\"/content/drive/MyDrive/pre_parquet\")\n"
      ],
      "metadata": {
        "id": "2_ATT1SR98om"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kHXbmM5BxHrc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pre_df.show(10)"
      ],
      "metadata": {
        "id": "ZQQhn5xqp6HF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "1ZeHJYcudQjr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking for missing values\n"
      ],
      "metadata": {
        "id": "vADMn2JpdUVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for missing values\n",
        "pre_df = pre_df.replace(\"NULL\", None)\n",
        "pre_df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in pre_df.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvwduZe6dGU4",
        "outputId": "485e639b-f6f7-4dfd-c1bc-2375a5829b38"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----+-------+------+----+-----------+--------+---------+-----+------------+-------+----------+------+---------+-------+--------------+------+-----+----+-----+-----+\n",
            "|business_id|name|address|state_|city|postal_code|latitude|longitude|stars|review_count|is_open|categories| hours|review_id|user_id|customer_stars|useful|funny|cool|text_|date_|\n",
            "+-----------+----+-------+------+----+-----------+--------+---------+-----+------------+-------+----------+------+---------+-------+--------------+------+-----+----+-----+-----+\n",
            "|          0|   0|  13409|     0|   0|        384|       0|        0|    0|           0|      0|         0|216501|        0|      0|             0|     0|    0|   0|    1|    0|\n",
            "+-----------+----+-------+------+----+-----------+--------+---------+-----+------------+-------+----------+------+---------+-------+--------------+------+-----+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check for missing values\n",
        "post_df = post_df.replace(\"NULL\", None)\n",
        "post_df.select([sum(col(c).isNull().cast(\"int\")).alias(c) for c in post_df.columns]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P8BIwGWdf_m",
        "outputId": "7a9fa8da-0922-42e4-8620-c807b47ad436"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----+-------+------+----+-----------+--------+---------+-----+------------+-------+----------+-----+---------+-------+--------------+------+-----+----+-----+-----+\n",
            "|business_id|name|address|state_|city|postal_code|latitude|longitude|stars|review_count|is_open|categories|hours|review_id|user_id|customer_stars|useful|funny|cool|text_|date_|\n",
            "+-----------+----+-------+------+----+-----------+--------+---------+-----+------------+-------+----------+-----+---------+-------+--------------+------+-----+----+-----+-----+\n",
            "|          0|   0|    992|     0|   0|          4|       0|        0|    0|           0|      0|         0|12232|        0|      0|             0|     0|    0|   0|    0|    0|\n",
            "+-----------+----+-------+------+----+-----------+--------+---------+-----+------------+-------+----------+-----+---------+-------+--------------+------+-----+----+-----+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both datasets have some missing values in address,hours and postal code columns.\n",
        "Since we will mostly focus on the reviews we decided to not drop them.\n",
        "Only the one missing review was removed."
      ],
      "metadata": {
        "id": "G4vucra9fTIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df = pre_df.dropna(subset=[\"text_\"])"
      ],
      "metadata": {
        "id": "rjiWp270fSux"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing duplicated reviews"
      ],
      "metadata": {
        "id": "ErG_LeLCfqJa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "lb6tURWQs2fq"
      },
      "outputs": [],
      "source": [
        "# Checking for duplicated values\n",
        "#print(pre_df.count())\n",
        "pre_df = pre_df.dropDuplicates()\n",
        "#print(pre_df.count())\n",
        "# there are no duplicated rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "8dhj0dNgtPFQ"
      },
      "outputs": [],
      "source": [
        "# Checking for duplicated values\n",
        "#print(post_df.count())\n",
        "post_df = post_df.dropDuplicates()\n",
        "#print(post_df.count())\n",
        "# there are no duplicated rows"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing identical reviews made from the same user about a specific business"
      ],
      "metadata": {
        "id": "N8E3kmVR7P8Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Z12pxUznz1eE"
      },
      "outputs": [],
      "source": [
        "# Drop duplicate reviews (same user, business, and text)\n",
        "post_df = post_df.dropDuplicates([\"user_id\", \"business_id\", \"text_\"])\n",
        "#post_df.count()\n",
        "# Number of rows before removing duplicated reviews: 400295"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xFB1RzzO0DBT"
      },
      "outputs": [],
      "source": [
        "# Drop duplicate reviews (same user, business, and text)\n",
        "pre_df = pre_df.dropDuplicates([\"user_id\", \"business_id\", \"text_\"])\n",
        "#pre_df.count()\n",
        "# Number of rows before removing duplicated reviews: 5172198"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date Range of Post and Pre Covid dataset"
      ],
      "metadata": {
        "id": "T1WJrcHUCjbe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tG5ASqEoxqXM"
      },
      "outputs": [],
      "source": [
        "print('Date Range Pre-Covid:', pre_df.select(min('date_')).collect()[0][0], '-', pre_df.select(max('date_')).collect()[0][0])\n",
        "print('Date Range Post-Covid:', post_df.select(min('date_')).collect()[0][0], '-', post_df.select(max('date_')).collect()[0][0])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " The first American case was reported on January 20, and Health and Human Services Secretary Alex Azar declared a public health emergency on January 31.\n",
        " https://en.wikipedia.org/wiki/COVID-19_pandemic_in_the_United_States"
      ],
      "metadata": {
        "id": "-juEMopY6w3Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finding reviews before covid started in USA"
      ],
      "metadata": {
        "id": "iuiYdlA97wDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_covid_reviews = post_df.filter(col(\"date_\")< to_timestamp(lit(\"2020-01-20 00:00:01\")))\n",
        "#pre_covid_reviews.count()"
      ],
      "metadata": {
        "id": "7ooZoDxxMrYZ"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " There are 31633 reviews that were written before 20/01,which was when the first covid case was reported in America"
      ],
      "metadata": {
        "id": "vlzopfLv64qY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing those reviews from the post covid dataset"
      ],
      "metadata": {
        "id": "XWB0IJ887347"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "post_df =post_df.filter(col(\"date_\") >= to_timestamp(lit(\"2020-01-20 00:00:01\")))\n",
        "#post_df.count()"
      ],
      "metadata": {
        "id": "q6hBeU0POjMU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding those reviews in the pre covid dataset"
      ],
      "metadata": {
        "id": "XwUHhV-I7HLc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df = pre_df.union(pre_covid_reviews)\n",
        "#pre_df.show()"
      ],
      "metadata": {
        "id": "FT_agwrtPVlM"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8W88kej4i6S"
      },
      "source": [
        "Checking if each business id has a unique name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PvscN5zo3Duc"
      },
      "outputs": [],
      "source": [
        "print('unique names:', pre_df.select(\"name\").distinct().count())\n",
        "print('unique ids:', pre_df.select('business_id').distinct().count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGGyq0yr2-ZJ"
      },
      "outputs": [],
      "source": [
        "print('unique names:', post_df.select(\"name\").distinct().count())\n",
        "print('unique ids:', post_df.select('business_id').distinct().count())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Location"
      ],
      "metadata": {
        "id": "hrJw4R_TMW2k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Location - Preprocessing - Post df"
      ],
      "metadata": {
        "id": "pYNu4Eo4ZTgT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing unique Cities\n",
        "post_df.select(col(\"city\")).distinct().count()"
      ],
      "metadata": {
        "id": "em-TMi3PoI9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can notice at first the post covid dataset contained 392 distinct cities, but with a detailed inspection we observed that there was similar cities just written differentlty."
      ],
      "metadata": {
        "id": "mWkSmFe07EMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's clean and normalize city column\n",
        "# Converting the first letters to capital ones and by using trim we remove\n",
        "# extra spaces\n",
        "# initcamp convert the column to title case, where the first letter is always capital\n",
        "post_df=post_df.withColumn(\"city\",initcap(trim(col(\"city\"))))\n",
        "#post_df.show()"
      ],
      "metadata": {
        "id": "wvArB4g63w_A"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_df.select(col(\"city\")).distinct().count()"
      ],
      "metadata": {
        "id": "z30ilxFb4zwY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can notice that the unique cities\n",
        "are reduced to 358."
      ],
      "metadata": {
        "id": "pjxZAWAM8AoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing any punctuations and extra spaces for comparison\n",
        "# e.g. St.Cloud now will be stcloud\n",
        "post_df = post_df.withColumn(\"city_key\", lower(regexp_replace(col(\"city\"), r\"[^a-zA-Z0-9]\", \"\")))"
      ],
      "metadata": {
        "id": "VBJ2jnov8GcX"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see how many cities we have with the same key\n",
        "post_df.groupBy(\"city_key\", \"city\").count().orderBy(\"city_key\").show(360, truncate=False)"
      ],
      "metadata": {
        "id": "JZ9fogy78Gfo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating window to rank cities by count per city_key\n",
        "# For each group of rows with the same city_key sort them by how often they appear\n",
        "# By using window we create a subset of dataframe where all rows have the same key\n",
        "# and within each window rows are ordered by the count in descending order\n",
        "windowSpec = Window.partitionBy(\"city_key\").orderBy(col(\"count\").desc())\n",
        "\n",
        "# Counting how many times city name appears per city\n",
        "city_counts = post_df.groupBy(\"city_key\", \"city\").count()\n",
        "\n",
        "# Picking the most common city_clean for each city_key\n",
        "standard_cities = city_counts.withColumn(\"rank\", row_number().over(windowSpec)).filter(col(\"rank\") == 1)\n",
        "\n",
        "### Now we have a standarized column, e.g. stcloud-> St. Cloud\n",
        "#### we don't have multiple variations like stcloud, St.  Cloud and St.CLoud etc"
      ],
      "metadata": {
        "id": "gRH2Tj91-0HN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### Explanation of window\n",
        "https://spark.apache.org/docs/latest/api/python/reference/pyspark.sql/api/pyspark.sql.Window.html\n",
        "\n",
        "\n",
        "Break data into groups based on city key (all rows same city key are groupped together)."
      ],
      "metadata": {
        "id": "qassAav9s9gp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the selected column\n",
        "standard_cities = standard_cities.withColumnRenamed(\"city\", \"city_standardized\")\n",
        "\n",
        "# Preforming join to have a final dataframe\n",
        "post_df = post_df.join(\n",
        "    standard_cities.select(\"city_key\", \"city_standardized\"),\n",
        "    on=\"city_key\",\n",
        "    how=\"left\"\n",
        ")"
      ],
      "metadata": {
        "id": "bndPly81-0Mb"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping city key and city columns, because they are not useful\n",
        "post_df=post_df.drop(\"city_key\", \"city\")"
      ],
      "metadata": {
        "id": "MWldQftT-0T8"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_df.show()"
      ],
      "metadata": {
        "id": "AjLVWaKqa9P7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_df.select(\"city_standardized\").distinct().count()"
      ],
      "metadata": {
        "id": "dkD6P5gD-0Ve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final unique cities  of our dataset\n",
        "are 349."
      ],
      "metadata": {
        "id": "7ITFtBNmJrhH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Location - Preprocessing - Pre df"
      ],
      "metadata": {
        "id": "7oLrqbl0Owj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the unique cities\n",
        "pre_df.select(col(\"city\")).distinct().count()"
      ],
      "metadata": {
        "id": "duKxgAFFdgAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At a first sight in the pre covid dataset we have a total of 450 cities.\n",
        "But lets check like before."
      ],
      "metadata": {
        "id": "hgyJ6YKHkpCo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Same approach we used in post covid dataframe."
      ],
      "metadata": {
        "id": "Cg0uNGXckVWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's clean and normalize city column\n",
        "# Converting the first letters to capital ones and by using trim we remove\n",
        "# extra spaces\n",
        "pre_df=pre_df.withColumn(\"city\",initcap(trim(col(\"city\"))))\n",
        "#pre_df.show()"
      ],
      "metadata": {
        "id": "tP_SmIB0kPj9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the unique cities\n",
        "pre_df.select(col(\"city\")).distinct().count()"
      ],
      "metadata": {
        "id": "GyE7wk7DlYwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we expected the unique cities are reduced. Now we have a total of 415."
      ],
      "metadata": {
        "id": "1sjfC_Mwletb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing any punctuations and extra spaces for comparison\n",
        "# e.g. St.Cloud now will be stcloud or St.  Cloud and St. Cloud are treated\n",
        "# as two distincts cities\n",
        "\n",
        "pre_df = pre_df.withColumn(\"city_key\", lower(regexp_replace(col(\"city\"), r\"[^a-zA-Z0-9]\", \"\")))"
      ],
      "metadata": {
        "id": "VxYnFYyWkPmt"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's see how many cities we have with the same key\n",
        "pre_df.groupBy(\"city_key\", \"city\").count().orderBy(\"city_key\").show(360, truncate=False)"
      ],
      "metadata": {
        "id": "joMgFQvPkPpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating window to rank cities by count per city_key\n",
        "# For each group of rows with the same city_key sort them by how often they appear\n",
        "windowSpec = Window.partitionBy(\"city_key\").orderBy(col(\"count\").desc())\n",
        "\n",
        "# Counting how many times city name appears per city\n",
        "city_counts = pre_df.groupBy(\"city_key\", \"city\").count()\n",
        "\n",
        "# Picking the most common city_clean for each city_key\n",
        "standard_cities = city_counts.withColumn(\"rank\", row_number().over(windowSpec)).filter(col(\"rank\") == 1)\n",
        "\n",
        "### Now we have a standarized column, e.g. stcloud-> St. Cloud"
      ],
      "metadata": {
        "id": "vx1vEuh8mLGW"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Renaming the selected column\n",
        "standard_cities = standard_cities.withColumnRenamed(\"city\", \"city_standardized\")\n",
        "\n",
        "# Preforming join to have a final dataframe\n",
        "pre_df = pre_df.join(\n",
        "    standard_cities.select(\"city_key\", \"city_standardized\"),\n",
        "    on=\"city_key\",\n",
        "    how=\"left\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "B8H_y8IQmLGX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping city key and city columns, because they are not useful\n",
        "pre_df=pre_df.drop(\"city_key\", \"city\")"
      ],
      "metadata": {
        "id": "2P7Hd8tkmuFg"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df.select(\"city_standardized\").distinct().count()"
      ],
      "metadata": {
        "id": "cpW_YfOnkPwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final total number of cities in the pre covid dataframe is 404."
      ],
      "metadata": {
        "id": "zngy49gcm-Jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### State"
      ],
      "metadata": {
        "id": "m88fu8GIPxUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### State - Post df"
      ],
      "metadata": {
        "id": "iSKI_bphbumV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the unique states\n",
        "post_df.select(col(\"state_\")).distinct().count()"
      ],
      "metadata": {
        "id": "zOO2eDy0oJAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ABE is not a regognized USA state so let's investigate further."
      ],
      "metadata": {
        "id": "4s-VTQXH-TB2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding rows with ABE state\n",
        "post_df.filter(col(\"state_\")==\"ABE\").count()"
      ],
      "metadata": {
        "id": "cyBy_hm19-tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the details for those 3 rows\n",
        "post_df.filter(col(\"state_\") == \"ABE\") \\\n",
        "    .select(\"name\", \"address\", \"city_standardized\", \"postal_code\", \"latitude\", \"longitude\") \\\n",
        "    .show(truncate=False)"
      ],
      "metadata": {
        "id": "mrQS6h2M-IZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is no state called ABE. Actually, the above restauraunts are in the Vancouver, British Columbia, Canada, so the correct province is BC."
      ],
      "metadata": {
        "id": "0YC_tn77_qzh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing to the correct province\n",
        "post_df=post_df.withColumn(\"state_\",\n",
        "                          when((col(\"state_\") == \"ABE\") & (col(\"city_standardized\") == \"Vancouver\"), \"BC\")\n",
        "    .otherwise(col(\"state_\"))\n",
        ")"
      ],
      "metadata": {
        "id": "IqX5JIBE_7eN"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if the changes are applied\n",
        "post_df.filter(col(\"state_\")==\"ABE\").count()"
      ],
      "metadata": {
        "id": "zwK8x65IAvps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_df.select(\"state_\").distinct().count()"
      ],
      "metadata": {
        "id": "ob7o1qCJAxuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "post_df.select(\"state_\").distinct().show()"
      ],
      "metadata": {
        "id": "F3YoaCEsEiv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion in the post covid dataset we have a total of  13  unique states."
      ],
      "metadata": {
        "id": "gQgwl1f3EcCz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### State - Pre df"
      ],
      "metadata": {
        "id": "GPAVNyhHng4d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the unique states\n",
        "pre_df.select(col(\"state_\")).distinct().count()"
      ],
      "metadata": {
        "id": "OT5QAI0MdgEG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The pre covid dataset contains 16 states.\n",
        "But let's check it like before."
      ],
      "metadata": {
        "id": "FlhRaLkttGEY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing Unique States\n",
        "pre_df.select(col(\"state_\")).distinct().show()"
      ],
      "metadata": {
        "id": "rVwcxM53hsX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keeping the same approach with pre covid dataset."
      ],
      "metadata": {
        "id": "yQwvycxeBYre"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding rows with ABE state\n",
        "pre_df.filter(col(\"state_\")==\"ABE\").count()"
      ],
      "metadata": {
        "id": "lNh3jw5HBMTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the details for those 11 rows\n",
        "pre_df.filter(col(\"state_\") == \"ABE\") \\\n",
        "    .select(\"name\", \"address\", \"city_standardized\", \"postal_code\", \"latitude\", \"longitude\") \\\n",
        "    .show(truncate=False)"
      ],
      "metadata": {
        "id": "6lZC9c4fBMTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Changing to the correct province\n",
        "pre_df=pre_df.withColumn(\"state_\",\n",
        "                          when((col(\"state_\") == \"ABE\") & (col(\"city_standardized\") == \"Vancouver\"), \"BC\")\n",
        "    .otherwise(col(\"state_\"))\n",
        ")"
      ],
      "metadata": {
        "id": "9hwkhyqOBMTM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if the changes are applied\n",
        "pre_df.filter(col(\"state_\")==\"ABE\").count()"
      ],
      "metadata": {
        "id": "87yP1PY4BMTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df.select(\"state_\").distinct().count()"
      ],
      "metadata": {
        "id": "t1WwdBebD28p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pre_df.select(col(\"state_\")).distinct().show()"
      ],
      "metadata": {
        "id": "S7JjS-rVE1hJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In conclusion we have 15 unique states in the pre dataset."
      ],
      "metadata": {
        "id": "aczg_u6bEO3h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Classification Modelling on Reviews column"
      ],
      "metadata": {
        "id": "tHE2AqFJHywX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are going to perform sentiment analysis, through Logistic Regression, in order to predict the category at which each review of each customer falls.\n",
        "1. We will first create a new columns that will be our label. This column will be called \"customer_stars_category\" and will be generated by the \"customer_stars\" as follows:\n",
        "- if \"customer_star\" == 4 OR 5 => \"customer_stars_category\" == \"Positive\"\n",
        "- if \"customer_star\" == 3 => \"customer_stars_category\" == \"Neutral\"\n",
        "- if \"customer_star\" == 1 OR 2 => \"customer_stars_category\" == \"Negative\"\n",
        "\n",
        "2. Then, we will filter out all the reviews that are not in English language.\n",
        "\n",
        "3. The next step will be a preprocessing step of the \"Reviews\" column. We will do TF-IDF in order to measure the importance of each word in the reviews collection. We will start by tokenizing the text and removing stopwords. After we will create a CountVectorizer, fit & transform. This will allows us to convert text data into a numerical format snce it will generate a matrix of term frequency counts for each review. Finally, we will use IDF to weight the word frequencies.\n",
        "\n",
        "4. Afterwards, we will continue with more pre-processing steps in other columns:\n",
        "  - Changing to the correct province (Vancouver is in BC not ABE).\n",
        "  - One-hot-encoding at the states column.\n",
        "\n",
        "5. Then, we split the dataset in train(80%) and test(20%) datasets.\n",
        "\n",
        "6. Then, we create the VectorAssembler that includes all the features that we will use to train the Logistic Regression model and label encode the label, \"customer_stars_category\" on train data.\n",
        "\n",
        "7. Train anf fit Logistic Regression on train data.\\\n",
        "   *Note: we set elastic net regularization to 1. This way we use Lasso - L1 regularization, which it basically automatically performs feature selection by setting some feature coefficients to zero. Features with non-zero coefficients are the ones that the model has learned to be important for predicting the target variable.*\n",
        "\n",
        "8. Create VectorAssembler for test data and label encode the label, \"customer_stars_category\" on test data.\n",
        "\n",
        "\n",
        "9. Make predictions\n",
        "\n",
        "10. Calculate metrics\n",
        "\n",
        "\n",
        "*Note: The above process will be performed at a random sample of 10% of the pre-covid dataset*"
      ],
      "metadata": {
        "id": "CTHlVC-ZHn_L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "First we start by taking a proportion of our dataset - we take the 10%\n",
        "\"\"\"\n",
        "\n",
        "sampled_pre_df3 = pre_df.sample(fraction=0.1, seed=42)"
      ],
      "metadata": {
        "id": "1wDt2VZxEpMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Printing schema of my sampled_pre_df dataset and shoe the first 5 cols\n",
        "\"\"\"\n",
        "sampled_pre_df3.printSchema()\n",
        "#sampled_pre_df3.show(5)"
      ],
      "metadata": {
        "id": "IHdm6aU9Er1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "1)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "Creating a new column named \"customer_stars_category\" and categorizing customer_stars column as it follows: 1,2 => negative, 3 => neutral, 4,5 => positive\n",
        "Then, cout how much i have from each category.\n",
        "\"\"\"\n",
        "from pyspark.sql.functions import when, col\n",
        "\n",
        "sampled_pre_df3 = sampled_pre_df3.withColumn(\n",
        "    \"customer_stars_category\",\n",
        "    when(col(\"customer_stars\").isin([4, 5]), \"positive\")\n",
        "    .when(col(\"customer_stars\").isin([1, 2]), \"negative\")\n",
        "    .otherwise(\"neutral\")\n",
        ")\n",
        "\n",
        "sampled_pre_df3.show(20, truncate=False)\n",
        "sampled_pre_df3.groupBy(\"customer_stars_category\").count().show()"
      ],
      "metadata": {
        "id": "gcv_dhUFEtkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "id": "u2btQB7hEw6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "2)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "Filter out all non-Enlgish reviews from the \"text_\" columns\n",
        "\"\"\"\n",
        "from pyspark.sql.functions import udf\n",
        "from pyspark.sql.types import StringType\n",
        "from langdetect import detect, DetectorFactory\n",
        "import langdetect\n",
        "\n",
        "# Set seed for consistent results\n",
        "DetectorFactory.seed = 42\n",
        "\n",
        "# Define UDF to detect language\n",
        "def detect_language(text):\n",
        "    try:\n",
        "        return detect(text)\n",
        "    except:\n",
        "        return \"unknown\"\n",
        "\n",
        "detect_language_udf = udf(detect_language, StringType())\n",
        "\n",
        "# Apply UDF to create a new column for language\n",
        "sampled_pre_df3 = sampled_pre_df3.withColumn(\"language\", detect_language_udf(sampled_pre_df3[\"text_\"]))\n",
        "\n",
        "# Filter the DataFrame to only include English-language reviews\n",
        "sampled_pre_df3 = sampled_pre_df3.filter(sampled_pre_df3[\"language\"] == \"en\")\n",
        "\n",
        "\n",
        "# Show rows where the text is not English\n",
        "#sampled_pre_df_with_sentiment.filter(sampled_pre_df_with_sentiment[\"language\"] != \"en\").select(\"text_\", \"language\").show()"
      ],
      "metadata": {
        "id": "lpXUD5z-E0Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sampled_pre_df3.show(10)"
      ],
      "metadata": {
        "id": "vivS4EeHE2tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "3) A)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "We preprocess the review column (\"text_\") (1)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "starting by tokenize and remove stop words from the reviews column\n",
        "\"\"\"\n",
        "sampled_pre_df_dataset_filtered3 = sampled_pre_df3.dropna() #filtering out NAs\n",
        "tokenizer2 = RegexTokenizer(inputCol=\"text_\", outputCol=\"words\", pattern=\"\\\\W\")\n",
        "\n",
        "tokenized_raw3 = tokenizer2.transform(sampled_pre_df_dataset_filtered3)\n",
        "print(\"--- tokenized reviews ---\")\n",
        "tokenized_raw3.select(\"words\").show(5)\n",
        "\n",
        "remover3 = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "df_cleaned3 = remover3.transform(tokenized_raw3)\n",
        "print(\"--- remove stop words from reviews ---\")\n",
        "df_cleaned3.select(\"filtered\").show(5)"
      ],
      "metadata": {
        "id": "hDDP1xsrFEqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "3) B)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "Now, we create a CountVectorizer, fit & transform\n",
        "This will allows us to convert text data into a numerical format.\n",
        "It will generate a matrix of term frequency counts for each review\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "For CountVectorizer we use as input the column that was the output from the StopWordsRemover. In addition, set vocabSize=5000, minDF=10.0\n",
        "\"\"\"\n",
        "from pyspark.ml.feature import CountVectorizer\n",
        "\n",
        "cv3 = CountVectorizer(inputCol=\"filtered\", outputCol=\"raw_features\", vocabSize=5000, minDF=10.0)\n",
        "cvmodel3 = cv3.fit(df_cleaned3)\n",
        "result_cv3 = cvmodel3.transform(df_cleaned3)\n",
        "#result_cv3.show(5)"
      ],
      "metadata": {
        "id": "KZU5qI2ZFHCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lO32vy6mDoHT"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "3) C)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "Continue with preprocess of Reviews column (3)\n",
        "Here, we use IDF to weight the word frequencies.\n",
        "\"\"\"\n",
        "idf3 = IDF(inputCol=\"raw_features\", outputCol=\"reviews\")\n",
        "idfModel3 = idf3.fit(result_cv3)\n",
        "result_tfidf3 = idfModel3.transform(result_cv3)\n",
        "#result_tfidf3.show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-05YWLbaD2E1"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "4) A)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "Changing to the correct province\n",
        "\"\"\"\n",
        "result_tfidf3=result_tfidf3.withColumn(\"state_\",\n",
        "                          when((col(\"state_\") == \"ABE\") & (col(\"city\") == \"Vancouver\"), \"BC\")\n",
        "    .otherwise(col(\"state_\"))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "4) B)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "state_: Apply one-hot encoding at the \"states\" column\n",
        "\"\"\"\n",
        "from pyspark.ml.feature import OneHotEncoder\n",
        "states = [(\"MN\",), (\"OR\",), (\"KY\",), (\"BC\",), (\"NH\",), (\"WA\",), (\"OH\",), (\"TX\",),(\"GA\",), (\"MA\",), (\"KS\",), (\"FL\",), (\"CO\",)]\n",
        "states_df = spark.createDataFrame(states, [\"state_\"])\n",
        "\n",
        "states_indexer = StringIndexer(inputCol=\"state_\", outputCol=\"state_index\")\n",
        "\n",
        "states_encoder = OneHotEncoder(inputCol=\"state_index\", outputCol=\"state_ohe\")\n",
        "\n",
        "pipeline = Pipeline(stages=[states_indexer, states_encoder])\n",
        "\n",
        "pipeline_model = pipeline.fit(states_df)\n",
        "df_encoded = pipeline_model.transform(states_df)\n",
        "result_tfidf3 = result_tfidf3.join(\n",
        "    df_encoded.select(\"state_\", \"state_index\", \"state_ohe\"),\n",
        "    on=\"state_\",\n",
        "    how=\"left\"\n",
        ")"
      ],
      "metadata": {
        "id": "T1vLRPYtFPkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "5)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "We split to train and test\n",
        "\"\"\"\n",
        "train_data, test_data = result_tfidf3.randomSplit([0.8, 0.2], seed=42)"
      ],
      "metadata": {
        "id": "nM0AiEoFFXRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "6)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "We create the VectorAssembler that includes all the features on train data\n",
        "\"\"\"\n",
        "assembler_lr = VectorAssembler(\n",
        "    inputCols=[\"latitude\",\"longitude\",\"useful\",\"funny\",\"cool\",\"review_count\",\"stars\", \"state_ohe\", \"is_open\",\"reviews\"],\n",
        "    outputCol=\"all_features\"\n",
        ")\n",
        "df_final_train = assembler_lr.transform(train_data)"
      ],
      "metadata": {
        "id": "wl21-4RYFY_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df_final_train.show(5)"
      ],
      "metadata": {
        "id": "9uuOvlQ4I6rk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Label Encoding the \"customer_stars_category\"\n",
        "df_final_train = df_final_train.withColumn(\n",
        "    \"customer_stars_category_labeled\",when((col(\"customer_stars_category\") == \"positive\"), 0).when((col(\"customer_stars_category\") == \"neutral\"), 1).otherwise(2)\n",
        ")"
      ],
      "metadata": {
        "id": "aOUz_K58Fc7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "7)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "Perform logistic regression\n",
        "\"\"\"\n",
        "#Train logistic regression\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "lr = LogisticRegression(maxIter=15,regParam=0.03,elasticNetParam=1,featuresCol=\"all_features\", labelCol=\"customer_stars_category_labeled\")\n",
        "lr_model = lr.fit(df_final_train)"
      ],
      "metadata": {
        "id": "5E6GgCdFFfk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "8)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "We create the VectorAssembler that includes all the features on test data\n",
        "\"\"\"\n",
        "assembler_lr_test = VectorAssembler(\n",
        "    inputCols=[\"latitude\",\"longitude\",\"useful\",\"funny\",\"cool\",\"review_count\",\"stars\", \"state_ohe\", \"is_open\",\"reviews\"],\n",
        "    outputCol=\"all_features\"\n",
        ")\n",
        "df_final_test = assembler_lr_test.transform(test_data)"
      ],
      "metadata": {
        "id": "oC2AcjghFiGu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_final_test = df_final_test.withColumn(\n",
        "    \"customer_stars_category_labeled\",when((col(\"customer_stars_category\") == \"positive\"), 0).when((col(\"customer_stars_category\") == \"neutral\"), 1).otherwise(2)\n",
        ")"
      ],
      "metadata": {
        "id": "NfSQbYrOFj2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "9)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "Make predictions\n",
        "\"\"\"\n",
        "\n",
        "predictions = lr_model.transform(df_final_test)\n",
        "predictions.select(\"customer_stars_category_labeled\", \"prediction\").show(10)"
      ],
      "metadata": {
        "id": "FMHXGgo5Flh6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "10)\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "Calculate metrics\n",
        "\"\"\"\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"customer_stars_category_labeled\",\n",
        "                                              predictionCol=\"prediction\",\n",
        "                                              metricName=\"f1\")\n",
        "\n",
        "f1_score = evaluator.evaluate(predictions)\n",
        "\n",
        "print(f\"Test F1-score: {f1_score}\")"
      ],
      "metadata": {
        "id": "iZS0bsb6FnZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation system Pre-Covid"
      ],
      "metadata": {
        "id": "mATj9pGrbH9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_pre_df3 = pre_df.sample(fraction=0.1, seed=42)\n",
        "sampled_pre_df3 = sampled_pre_df3.sample(fraction=0.5, seed=42)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "dFGzUDUz2arA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_pre_df3.count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxv12AFDFsEU",
        "outputId": "08fc64c2-d185-443a-96b6-d07c70850a34"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "259049"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Index the `user_id` and `business_id` columns to take numerical values\n",
        "user_indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\", handleInvalid=\"keep\")\n",
        "business_indexer = StringIndexer(inputCol=\"business_id\", outputCol=\"business_index\", handleInvalid=\"keep\")\n",
        "\n",
        "# Fit and transform to get indexed columns\n",
        "df_indexed = user_indexer.fit(sampled_pre_df3).transform(sampled_pre_df3)\n",
        "df_indexed = business_indexer.fit(df_indexed).transform(df_indexed)\n",
        "\n",
        "#  Check the schema after indexing to ensure proper data types\n",
        "df_indexed.printSchema()\n",
        "\n",
        "# Prepare data for ALS (Use indexed columns for user and business)\n",
        "df_clean = df_indexed.select(\"user_index\", \"business_index\", \"customer_stars\")\n",
        "\n",
        "#  Split the data into training and test sets\n",
        "(training_data, test_data) = df_clean.randomSplit([0.8, 0.2], seed=1234)\n",
        "\n",
        "# Train the ALS model\n",
        "als = ALS(maxIter=10, regParam=0.01, userCol=\"user_index\", itemCol=\"business_index\",\n",
        "          ratingCol=\"customer_stars\", coldStartStrategy=\"drop\")\n",
        "\n",
        "# Fit the model to the training data\n",
        "model = als.fit(training_data)\n",
        "\n",
        "#  Generate recommendations for all users\n",
        "user_recs = model.recommendForAllUsers(10)\n",
        "\n",
        "# Explode recommendations and select relevant columns\n",
        "user_recs = user_recs.selectExpr(\"user_index\", \"explode(recommendations) as recommendations\")\n",
        "user_recs = user_recs.selectExpr(\"user_index\", \"recommendations.business_index as business_index\",\n",
        "                                 \"recommendations.rating as rating\")\n",
        "\n",
        "# Show the results\n",
        "user_recs.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c23-UDmBbLil",
        "outputId": "dbc262e2-4a68-4195-e5b3-062ce999f9ad"
      },
      "execution_count": 41,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- business_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- address: string (nullable = true)\n",
            " |-- state_: string (nullable = true)\n",
            " |-- postal_code: string (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- stars: double (nullable = true)\n",
            " |-- review_count: integer (nullable = true)\n",
            " |-- is_open: integer (nullable = true)\n",
            " |-- categories: string (nullable = true)\n",
            " |-- hours: string (nullable = true)\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- customer_stars: integer (nullable = true)\n",
            " |-- useful: integer (nullable = true)\n",
            " |-- funny: integer (nullable = true)\n",
            " |-- cool: integer (nullable = true)\n",
            " |-- text_: string (nullable = true)\n",
            " |-- date_: timestamp (nullable = true)\n",
            " |-- city_standardized: string (nullable = true)\n",
            " |-- user_index: double (nullable = false)\n",
            " |-- business_index: double (nullable = false)\n",
            "\n",
            "+----------+--------------+---------+\n",
            "|user_index|business_index|   rating|\n",
            "+----------+--------------+---------+\n",
            "|         1|         13683| 7.289673|\n",
            "|         1|          8445|6.5830517|\n",
            "|         1|          5042|6.5710177|\n",
            "|         1|          8905|6.5397544|\n",
            "|         1|         17826| 6.493511|\n",
            "|         1|         11174|6.4780416|\n",
            "|         1|          7178|6.4727364|\n",
            "|         1|          9003| 6.467161|\n",
            "|         1|          2449|6.3717465|\n",
            "|         1|         12350|6.3574986|\n",
            "|         3|         15853|7.7097898|\n",
            "|         3|          5426|  7.48718|\n",
            "|         3|         13683|7.4542327|\n",
            "|         3|          5735|7.3365283|\n",
            "|         3|          6139|7.2568827|\n",
            "|         3|          6076|7.2033544|\n",
            "|         3|         16023|7.0986233|\n",
            "|         3|          9684| 7.077441|\n",
            "|         3|          3666|7.0393605|\n",
            "|         3|         28155|6.9925203|\n",
            "+----------+--------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"customer_stars\",\n",
        "                                predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CB0cBQecqOU",
        "outputId": "00d84db1-e239-48e3-e6bc-8731979bb4de"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 2.1714276503917826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the recommendations for a specific user\n",
        "user_id = 2\n",
        "\n",
        "user_rec = user_recs.filter(user_recs.user_index == user_id)\n",
        "\n",
        "print(\"Businesses rated by user with index \" + str(user_id))\n",
        "# Show the movies rated by the user\n",
        "user_ratings = df_indexed.filter(df_indexed.user_index == user_id)\\\n",
        "    .select(\"name\", \"categories\", \"customer_stars\")\n",
        "\n",
        "user_ratings.show(100,truncate=False)\n",
        "\n",
        "# Show the top 10 recommendations for the specific user\n",
        "user_rec = user_recs.filter(user_recs.user_index== user_id)\n",
        "\n",
        "# Print and show the recommendations\n",
        "user_rec.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdTQgcddibIF",
        "outputId": "64ba3f09-1da4-431e-a840-65fd7fb03549"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Businesses rated by user with index 2\n",
            "+------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------+\n",
            "|name                                      |categories                                                                                                                                       |customer_stars|\n",
            "+------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------+\n",
            "|Freshslice Pizza                          |Restaurants, Pizza                                                                                                                               |3             |\n",
            "|Ramen Danbo                               |Ramen, Japanese, Noodles, Restaurants                                                                                                            |4             |\n",
            "|Bubble World                              |Chinese, Coffee & Tea, Bubble Tea, Food, Restaurants, Taiwanese                                                                                  |3             |\n",
            "|Dairy Queen Grill & Chill                 |Fast Food, Food, Ice Cream & Frozen Yogurt, Restaurants                                                                                          |3             |\n",
            "|Safeway                                   |Food, Delis, Sandwiches, Restaurants, Grocery                                                                                                    |3             |\n",
            "|Glowbal Grill Steaks & Satay              |Restaurants, Canadian (New), American (New), Steakhouses                                                                                         |5             |\n",
            "|Bella Pizza                               |Restaurants, Pizza, Food Delivery Services, Food                                                                                                 |4             |\n",
            "|EXP Restaurant + Bar                      |Canadian (New), Bars, Pubs, Nightlife, Restaurants, Burgers                                                                                      |2             |\n",
            "|Match Eatery And Public House             |Lounges, Restaurants, Canadian (New), Nightlife, Bars, Comfort Food, Pubs, Gastropubs                                                            |3             |\n",
            "|McDonald's                                |Burgers, Fast Food, Restaurants                                                                                                                  |3             |\n",
            "|Axum Restaurant                           |Ethiopian, Restaurants                                                                                                                           |4             |\n",
            "|Blenz Coffee                              |Food, Coffee & Tea, Restaurants, Sandwiches                                                                                                      |2             |\n",
            "|Stepho's Souvlaki Greek Taverna           |Specialty Food, Restaurants, Sandwiches, Greek, Mediterranean, Ethnic Food, Food                                                                 |4             |\n",
            "|Church's Chicken                          |Chicken Wings, Restaurants, Fast Food, Soul Food, Southern                                                                                       |4             |\n",
            "|Smoke and Bones                           |Barbeque, Caterers, Event Planning & Services, Restaurants, Street Vendors, Food, American (Traditional), Burgers                                |4             |\n",
            "|Watami                                    |Restaurants, Japanese, Sushi Bars                                                                                                                |3             |\n",
            "|Red Pagoda                                |Restaurants, Vietnamese                                                                                                                          |3             |\n",
            "|Oyster                                    |Barbeque, Bars, Restaurants, Live/Raw Food, Seafood, Nightlife                                                                                   |4             |\n",
            "|Malone's Social Lounge and Taphouse       |Nightlife, Bars, Restaurants, Food, Sports Bars, Karaoke, Arts & Entertainment, Beer, Wine & Spirits, Lounges, Pubs                              |3             |\n",
            "|PappaRoti                                 |Food, Desserts, Coffee & Tea, Sandwiches, Bakeries, Juice Bars & Smoothies, Restaurants                                                          |3             |\n",
            "|The Dawg House                            |Hot Dogs, Restaurants, Food Stands, Food                                                                                                         |4             |\n",
            "|McDonald's                                |Restaurants, Fast Food, Burgers, Food, Coffee & Tea                                                                                              |3             |\n",
            "|Elephant & Castle                         |Nightlife, British, Restaurants, Bars, Pubs                                                                                                      |4             |\n",
            "|Subway                                    |Restaurants, Fast Food, Sandwiches                                                                                                               |2             |\n",
            "|One20 Public House                        |Canadian (New), Bars, Beer, Wine & Spirits, Restaurants, Gastropubs, Nightlife, Pubs, Food, Cocktail Bars                                        |3             |\n",
            "|Quiznos                                   |Fast Food, Sandwiches, Restaurants                                                                                                               |4             |\n",
            "|Pumphouse Taproom                         |Restaurants, Nightlife, American (Traditional), Pubs, Bars                                                                                       |3             |\n",
            "|House of Tofu Soup                        |Restaurants, Korean                                                                                                                              |4             |\n",
            "|Richmond Public Market                    |Grocery, Shopping Centers, Restaurants, Food, Arts & Entertainment, Shopping, Chinese, Public Markets                                            |4             |\n",
            "|Harold's Kitchen & Bar                    |Restaurants, Pubs, Nightlife, Bars, Canadian (New), American (New)                                                                               |3             |\n",
            "|Freshslice Pizza                          |Restaurants, Pizza                                                                                                                               |4             |\n",
            "|Bubble World                              |Bubble Tea, Restaurants, Taiwanese, Coffee & Tea, Chinese, Food                                                                                  |3             |\n",
            "|Cypress Mountain Crazy Raven Bar and Grill|Bars, Burgers, Food, Nightlife, Restaurants                                                                                                      |4             |\n",
            "|Hubbub                                    |Sandwiches, Restaurants, Food, Soup, Salad                                                                                                       |3             |\n",
            "|Subeez Cafe                               |Cafes, Pubs, Nightlife, Lounges, Breakfast & Brunch, Bars, Canadian (New), Restaurants, Wine Bars, American (New)                                |4             |\n",
            "|Caf Zen On Yew                           |Restaurants, Breakfast & Brunch                                                                                                                  |3             |\n",
            "|Waves Coffee House                        |Food, Cafes, Restaurants, Coffee & Tea                                                                                                           |4             |\n",
            "|House Special                             |Restaurants, Tapas/Small Plates, Vietnamese, Nightlife, Vegetarian, Cocktail Bars, Bars                                                          |4             |\n",
            "|Pho Hue                                   |Restaurants, Vietnamese                                                                                                                          |4             |\n",
            "|Copa Caf                                 |Food, Coffee & Tea, Restaurants, Chinese                                                                                                         |3             |\n",
            "|Lips Resto                                |Nightlife, Bars, Tapas/Small Plates, Restaurants, Canadian (New), Lounges                                                                        |3             |\n",
            "|Hard Rock Casino Vancouver                |Casinos, Nightlife, Music Venues, Arts & Entertainment, Restaurants, Buffets                                                                     |4             |\n",
            "|Lam Hoa Quan Restaurant                   |Restaurants, Vietnamese                                                                                                                          |3             |\n",
            "|Tim Hortons                               |Breakfast & Brunch, Restaurants, Donuts, Food, Coffee & Tea                                                                                      |3             |\n",
            "|Claypot Hot Pot & BBQ                     |Hot Pot, Barbeque, Chinese, Restaurants                                                                                                          |4             |\n",
            "|Urban Fare                                |Pizza, Food, Buffets, Restaurants, Grocery                                                                                                       |2             |\n",
            "|Morning Star Bubble Tea                   |Taiwanese, Food, Restaurants, Bubble Tea                                                                                                         |2             |\n",
            "|Strike                                    |Restaurants, Taiwanese, Tapas/Small Plates, Chinese                                                                                              |3             |\n",
            "|Lulu's Lounge                             |Bars, Restaurants, Lounges, American (New), Canadian (New), Nightlife                                                                            |3             |\n",
            "|Bang Bang                                 |Bars, Thai, Gluten-Free, Nightlife, Wine Bars, Cocktail Bars, Restaurants                                                                        |3             |\n",
            "|Shenanigans                               |Nightlife, Restaurants, Pubs, Canadian (New), Bars                                                                                               |3             |\n",
            "|The Mac Shack                             |Restaurants, Canadian (New), Fast Food, American (New)                                                                                           |4             |\n",
            "|Burger King                               |Burgers, Restaurants                                                                                                                             |3             |\n",
            "|WINGS Burnaby                             |Sports Bars, Pubs, Burgers, Nightlife, Restaurants, Chicken Wings, Beer, Wine & Spirits, Food, Canadian (New), Bars                              |4             |\n",
            "|Bubble Queen                              |Bubble Tea, Food, Waffles, Coffee & Tea, Oriental, Taiwanese, Restaurants, Cafes                                                                 |4             |\n",
            "|Library Square                            |Sports Bars, Nightlife, Bars, Music Venues, Event Planning & Services, Restaurants, Pubs, Venues & Event Spaces, Arts & Entertainment, Gastropubs|3             |\n",
            "|Freshslice Pizza                          |Pizza, Restaurants                                                                                                                               |3             |\n",
            "|Pearl Castle Caf                         |Food, Bubble Tea, Chinese, Restaurants, Cafes, Coffee & Tea, Taiwanese                                                                           |3             |\n",
            "|Domo Sushi                                |Sushi Bars, Restaurants                                                                                                                          |3             |\n",
            "|Pho Win                                   |Vietnamese, Food, Restaurants, Soup                                                                                                              |5             |\n",
            "|Cazba                                     |Restaurants, Persian/Iranian, Middle Eastern                                                                                                     |4             |\n",
            "|Yellow Dog Brewing                        |Breweries, Brasseries, Food, Restaurants, Local Flavor                                                                                           |4             |\n",
            "|Burger King                               |Fast Food, Burgers, Restaurants                                                                                                                  |3             |\n",
            "|The Cannibal Cafe                         |Diners, Restaurants, Burgers, Food                                                                                                               |3             |\n",
            "|Shark Club Sports Bar & Grill             |Chicken Wings, Restaurants, Sports Bars, Bars, Nightlife, Food, Canadian (New), Lounges                                                          |4             |\n",
            "|The Blackbird Public House                |Bars, Restaurants, Nightlife, Canadian (New)                                                                                                     |3             |\n",
            "|El Furniture Warehouse - Granville        |Furniture Stores, Restaurants, Mexican, American (Traditional), Shopping, Nightlife, Home & Garden, Bars, Comfort Food                           |2             |\n",
            "|Got Pho                                   |Restaurants, Vietnamese                                                                                                                          |4             |\n",
            "|Toby's Pub                                |Restaurants, Bars, Pubs, Food, Canadian (New), Beer, Wine & Spirits, Nightlife                                                                   |4             |\n",
            "|Victoria Chinese Restaurant               |Chinese, Seafood, Dim Sum, Restaurants                                                                                                           |3             |\n",
            "|Burger King                               |Fast Food, Restaurants, Burgers                                                                                                                  |3             |\n",
            "|E Tea                                     |Food, Restaurants, Fast Food, Taiwanese, Tea Rooms                                                                                               |4             |\n",
            "|Cactus Club Cafe                          |American (New), Restaurants, Bars, Cafes, Cocktail Bars, Canadian (New), Burgers, Nightlife, Food Delivery Services, Food                        |4             |\n",
            "|Blenz Coffee                              |Food, Coffee & Tea, Restaurants, Sandwiches                                                                                                      |2             |\n",
            "|Gokudo Shabu Shabu-Burnaby                |Restaurants, Hot Pot                                                                                                                             |4             |\n",
            "|Illumination Summer Night Market          |Shopping, Ethnic Food, Street Vendors, Food Stands, Arcades, Local Flavor, Food, Arts & Entertainment, Restaurants, Specialty Food, Grocery      |3             |\n",
            "|Tea Wok Asian Cuisine                     |Restaurants, Taiwanese, Food, Juice Bars & Smoothies, Vegan, Tea Rooms, Chinese                                                                  |3             |\n",
            "|Best Falafel                              |Food, Specialty Food, Mediterranean, Restaurants, Local Flavor, Falafel, Halal, Lebanese, Middle Eastern, Ethnic Food                            |3             |\n",
            "|Victoria Chinese Restaurant               |Chinese, Seafood, Dim Sum, Restaurants                                                                                                           |4             |\n",
            "|WINGS Burnaby                             |Sports Bars, Pubs, Burgers, Nightlife, Restaurants, Chicken Wings, Beer, Wine & Spirits, Food, Canadian (New), Bars                              |3             |\n",
            "|Earls Kitchen + Bar                       |Desserts, Cocktail Bars, Food, American (New), American (Traditional), Bars, Comfort Food, Restaurants, Nightlife, Canadian (New)                |4             |\n",
            "|Marcello Restorante & Pizzeria            |Pizza, Italian, Restaurants                                                                                                                      |4             |\n",
            "|Le Pho                                    |Specialty Food, Food, Restaurants, Vietnamese, Ethnic Food                                                                                       |4             |\n",
            "|Colony Bar                                |Restaurants, Bars, Nightlife                                                                                                                     |3             |\n",
            "|Sassafras Food Fair                       |Restaurants, Food, Food Court                                                                                                                    |2             |\n",
            "|Moxie's Grill & Bar                       |Nightlife, Steakhouses, Canadian (New), American (New), American (Traditional), Lounges, Restaurants, Bars                                       |3             |\n",
            "|Phnom Penh                                |Vietnamese, Cambodian, Restaurants                                                                                                               |5             |\n",
            "+------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------+--------------+\n",
            "\n",
            "+----------+--------------+---------+\n",
            "|user_index|business_index|rating   |\n",
            "+----------+--------------+---------+\n",
            "|2         |10351         |7.6246567|\n",
            "|2         |24383         |7.623864 |\n",
            "|2         |9481          |7.5630026|\n",
            "|2         |12164         |7.3680787|\n",
            "|2         |18164         |7.245963 |\n",
            "|2         |8418          |7.16605  |\n",
            "|2         |3665          |7.0676236|\n",
            "|2         |7139          |7.0492096|\n",
            "|2         |3308          |7.018407 |\n",
            "|2         |16398         |6.978895 |\n",
            "+----------+--------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2\n"
      ],
      "metadata": {
        "id": "n0icW_KMMAda"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_pre_df3 = pre_df.limit(100000)"
      ],
      "metadata": {
        "id": "KS0FiOcHMGQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Index the `user_id` and `business_id` columns to take numerical values\n",
        "user_indexer = StringIndexer(inputCol=\"user_id\", outputCol=\"user_index\", handleInvalid=\"keep\")\n",
        "business_indexer = StringIndexer(inputCol=\"business_id\", outputCol=\"business_index\", handleInvalid=\"keep\")\n",
        "\n",
        "# Fit and transform to get indexed columns\n",
        "df_indexed = user_indexer.fit(sampled_pre_df3).transform(sampled_pre_df3)\n",
        "df_indexed = business_indexer.fit(df_indexed).transform(df_indexed)\n",
        "\n",
        "#  Check the schema after indexing to ensure proper data types\n",
        "df_indexed.printSchema()\n",
        "\n",
        "# Prepare data for ALS (Use indexed columns for user and business)\n",
        "df_clean = df_indexed.select(\"user_index\", \"business_index\", \"customer_stars\")\n",
        "\n",
        "#  Split the data into training and test sets\n",
        "(training_data, test_data) = df_clean.randomSplit([0.8, 0.2], seed=1234)\n",
        "\n",
        "# Train the ALS model\n",
        "als = ALS(maxIter=10, regParam=0.01, userCol=\"user_index\", itemCol=\"business_index\",\n",
        "          ratingCol=\"customer_stars\", coldStartStrategy=\"drop\")\n",
        "\n",
        "# Fit the model to the training data\n",
        "model = als.fit(training_data)\n",
        "\n",
        "#  Generate recommendations for all users\n",
        "user_recs = model.recommendForAllUsers(10)\n",
        "\n",
        "# Explode recommendations and select relevant columns\n",
        "user_recs = user_recs.selectExpr(\"user_index\", \"explode(recommendations) as recommendations\")\n",
        "user_recs = user_recs.selectExpr(\"user_index\", \"recommendations.business_index as business_index\",\n",
        "                                 \"recommendations.rating as rating\")\n",
        "\n",
        "# Show the results\n",
        "user_recs.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ffbda5a-d71a-4fee-e6aa-d0aa7b2e8040",
        "id": "H8TdvsgZMFSY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- business_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- address: string (nullable = true)\n",
            " |-- state_: string (nullable = true)\n",
            " |-- postal_code: string (nullable = true)\n",
            " |-- latitude: double (nullable = true)\n",
            " |-- longitude: double (nullable = true)\n",
            " |-- stars: double (nullable = true)\n",
            " |-- review_count: integer (nullable = true)\n",
            " |-- is_open: integer (nullable = true)\n",
            " |-- categories: string (nullable = true)\n",
            " |-- hours: string (nullable = true)\n",
            " |-- review_id: string (nullable = true)\n",
            " |-- user_id: string (nullable = true)\n",
            " |-- customer_stars: integer (nullable = true)\n",
            " |-- useful: integer (nullable = true)\n",
            " |-- funny: integer (nullable = true)\n",
            " |-- cool: integer (nullable = true)\n",
            " |-- text_: string (nullable = true)\n",
            " |-- date_: timestamp (nullable = true)\n",
            " |-- city_standardized: string (nullable = true)\n",
            " |-- user_index: double (nullable = false)\n",
            " |-- business_index: double (nullable = false)\n",
            "\n",
            "+----------+--------------+---------+\n",
            "|user_index|business_index|   rating|\n",
            "+----------+--------------+---------+\n",
            "|         1|          3112| 7.986965|\n",
            "|         1|          1820|7.9819493|\n",
            "|         1|           658|7.7611947|\n",
            "|         1|          5229|7.6739936|\n",
            "|         1|          2469| 7.633798|\n",
            "|         1|          5288|7.4669027|\n",
            "|         1|           557| 7.400891|\n",
            "|         1|          4538| 7.377954|\n",
            "|         1|          5877|7.3501263|\n",
            "|         1|           240|7.2118144|\n",
            "|         3|          6706| 7.415812|\n",
            "|         3|           696|6.9180965|\n",
            "|         3|          9659|6.7330174|\n",
            "|         3|          1639|6.5783296|\n",
            "|         3|          4938|6.5749645|\n",
            "|         3|          4753| 6.525858|\n",
            "|         3|          2522|6.4634123|\n",
            "|         3|          3660|6.3893557|\n",
            "|         3|           809| 6.341212|\n",
            "|         3|           554|6.3323736|\n",
            "+----------+--------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "# Evaluate the model by computing the RMSE on the test data\n",
        "predictions = model.transform(test_data)\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"customer_stars\",\n",
        "                                predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(\"Root-mean-square error = \" + str(rmse))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa290b87-f01a-4f01-8797-c75d26b80e8f",
        "id": "lCMaOxXpMNkR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root-mean-square error = 4.222957018480883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show the recommendations for a specific user\n",
        "user_id = 2\n",
        "\n",
        "user_rec = user_recs.filter(user_recs.user_index == user_id)\n",
        "\n",
        "print(\"Businesses rated by user with index \" + str(user_id))\n",
        "# Show the movies rated by the user\n",
        "user_ratings = df_indexed.filter(df_indexed.user_index == user_id)\\\n",
        "    .select(\"name\", \"categories\", \"customer_stars\")\n",
        "\n",
        "user_ratings.show(100,truncate=False)\n",
        "\n",
        "# Show the top 10 recommendations for the specific user\n",
        "user_rec = user_recs.filter(user_recs.user_index== user_id)\n",
        "\n",
        "# Print and show the recommendations\n",
        "user_rec.show(truncate=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20cddf40-5696-4dab-eaf8-6307f5f3e6df",
        "id": "NuLqPx2_MPE8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Businesses rated by user with index 2\n",
            "+-------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+--------------+\n",
            "|name                                       |categories                                                                                                                                    |customer_stars|\n",
            "+-------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+--------------+\n",
            "|New Town Bakery & Restaurant               |Restaurants, Chinese, Dim Sum, Food, Bakeries                                                                                                 |3             |\n",
            "|Mad Greek Restaurant                       |Restaurants, Mediterranean, Specialty Food, Ethnic Food, Greek, Food                                                                          |3             |\n",
            "|Diner No.1                                 |American (Traditional), Restaurants, Diners                                                                                                   |4             |\n",
            "|Quiznos                                    |Sandwiches, Fast Food, Restaurants                                                                                                            |3             |\n",
            "|George's Taverna In Steveston              |Greek, Restaurants                                                                                                                            |4             |\n",
            "|Baru Latino                                |Restaurants, Latin American                                                                                                                   |5             |\n",
            "|Shoom Restaurant                           |Chinese, Restaurants                                                                                                                          |4             |\n",
            "|Nuba in Kitsilano                          |Restaurants, Halal, Lebanese, Mediterranean, Tapas/Small Plates, Vegetarian, Middle Eastern                                                   |3             |\n",
            "|Circus Play Cafe                           |Active Life, Playgrounds, Restaurants, Cafes                                                                                                  |4             |\n",
            "|Earls Kitchen + Bar                        |Comfort Food, American (New), Restaurants, Cocktail Bars, Bars, Nightlife, Canadian (New)                                                     |4             |\n",
            "|Indochine Kitchen + Bar                    |Bars, Asian Fusion, Restaurants, Nightlife                                                                                                    |5             |\n",
            "|Trocadero Pizza & Steak House              |Greek, Restaurants, Steakhouses, Pizza                                                                                                        |4             |\n",
            "|Thierry                                    |Food, Desserts, Chocolatiers & Shops, Food Delivery Services, Patisserie/Cake Shop, Specialty Food, Restaurants, Coffee & Tea, Cafes, Bakeries|4             |\n",
            "|Jasmine Halal Meats & Mediterranean Produce|Shopping, Grocery, Specialty Food, Meat Shops, Halal, Food, Middle Eastern, Restaurants                                                       |3             |\n",
            "|Senova Restaurant                          |Spanish, Restaurants, Italian, Basque                                                                                                         |4             |\n",
            "|Cardero's Restaurant & Marine Pub          |Restaurants, Cajun/Creole, Asian Fusion, Canadian (New), Nightlife, Seafood                                                                   |3             |\n",
            "|Subway                                     |Sandwiches, Fast Food, Restaurants                                                                                                            |2             |\n",
            "|Heart Stock Noodle & Tea                   |Coffee & Tea, Tea Rooms, Food, Vietnamese, Restaurants, Desserts                                                                              |3             |\n",
            "|Qoola Frozen Yogurt Bar                    |Canadian (New), Restaurants, Food, American (New), Ice Cream & Frozen Yogurt                                                                  |5             |\n",
            "|Triple O's                                 |Restaurants, Breakfast & Brunch, Burgers, Food                                                                                                |3             |\n",
            "|Shining Garden Restaurant                  |Restaurants, Specialty Food, Food, Chinese, Ethnic Food, Imported Food, Seafood                                                               |3             |\n",
            "|Bistro Hatzu                               |Event Planning & Services, Restaurants, Japanese, Food Delivery Services, Food, Tapas/Small Plates, Caterers, Sushi Bars                      |4             |\n",
            "|Bun Cha Ca Hoang Yen                       |Restaurants, Noodles, Vietnamese                                                                                                              |4             |\n",
            "|Suika                                      |Restaurants, Tapas/Small Plates, Sushi Bars, Japanese                                                                                         |4             |\n",
            "|Market Grill                               |Restaurants, Burgers                                                                                                                          |3             |\n",
            "|Chilli Lee                                 |Restaurants, Chinese, Food Delivery Services, Food                                                                                            |4             |\n",
            "|Orange Door                                |Chinese, Restaurants                                                                                                                          |3             |\n",
            "|Wendy's                                    |Burgers, Restaurants, Fast Food                                                                                                               |3             |\n",
            "|Freshslice Pizza                           |Pizza, Restaurants                                                                                                                            |3             |\n",
            "|Hi Genki                                   |Japanese, Restaurants, Asian Fusion                                                                                                           |4             |\n",
            "+-------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+--------------+\n",
            "\n",
            "+----------+--------------+---------+\n",
            "|user_index|business_index|rating   |\n",
            "+----------+--------------+---------+\n",
            "|2         |1165          |7.8201323|\n",
            "|2         |1349          |7.1293693|\n",
            "|2         |2215          |7.0188303|\n",
            "|2         |9029          |6.961105 |\n",
            "|2         |1626          |6.9134555|\n",
            "|2         |990           |6.8586392|\n",
            "|2         |484           |6.839792 |\n",
            "|2         |1724          |6.798312 |\n",
            "|2         |12895         |6.646365 |\n",
            "|2         |469           |6.6224008|\n",
            "+----------+--------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4t2EIRRsOf2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clusters"
      ],
      "metadata": {
        "id": "KAo68kq-Ogvw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xyzNtrGsOiwn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}